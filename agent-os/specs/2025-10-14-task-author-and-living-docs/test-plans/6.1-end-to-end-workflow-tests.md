# Test Plan 6.1: End-to-End Workflow Testing

## Overview
**Test Group:** 6.1 - End-to-End Workflow Testing
**Purpose:** Validate complete user workflows from session initialization through task creation and living document management
**Dependencies:** Phases 1-5 must be fully implemented
**Estimated Execution Time:** 45-60 minutes

## Test Environment Setup

### Prerequisites
- All Phase 1-5 features implemented and functional
- Clean test environment with no existing bert tasks
- Test files prepared:
  - Sample product documentation file
  - Sample codebase files for abstract request testing

### Test Data Preparation
Create the following test files:
1. `agent-os/product/test-roadmap.md` - Sample roadmap for task-author testing
2. `agent-os/test-files/auth-module.js` - Sample code file for abstract request testing

## Test Cases

### Test 6.1.1: Complete Task Authoring Workflow

**Test ID:** E2E-TASK-001
**Description:** Validate the complete workflow of creating and managing hierarchical tasks

#### Test Steps

**Step 1: Initialize Bert Session**
- Action: Execute `/agent-os:bert:start`
- Expected Result:
  - Success message confirming bert is active
  - Context instructions listing overlay and include directories
  - Examples of natural language invocation patterns
  - No errors

**Step 2: Create Parent Task from File**
- Action: Execute `/agent-os:bert:task-author agent-os/product/test-roadmap.md`
- Expected Result:
  - File is read and analyzed
  - Parent task file created: `agent-os/bert/tasks/task-0N-{slug}.md`
  - File contains valid frontmatter (status: pending, created: YYYY-MM-DD)
  - Task section contains multiple improvement items with checkboxes
  - Task numbers are formatted (e.g., N.01, N.02)
  - Rationale section explains why improvements matter
  - Confirmation message displays task file path and summary

**Step 3: Review Generated Parent Task**
- Action: Read the generated parent task file
- Expected Result:
  - Frontmatter is valid YAML
  - Task title matches pattern: `# Task N: {Title}`
  - Description explains analysis context
  - Tasks are specific and actionable
  - All tasks are unchecked `- [ ]`
  - Rationale provides meaningful context

**Step 4: Create First-Level Subtasks**
- Action: Execute `/agent-os:bert:task-create -p N` (where N is parent task number)
- Expected Result:
  - Subtask files created: `task-0N.1-*.md`, `task-0N.2-*.md`, etc.
  - Each subtask has proper frontmatter with `parent: N` field
  - Each subtask has task number in title: `# Task N.1: {Title}`
  - Parent task checkboxes updated with smart padding (e.g., N.01.1, N.01.2)
  - All parent task checkboxes remain unchecked

**Step 5: Create Second-Level Nested Subtasks**
- Action: Select one first-level subtask, execute `/agent-os:bert:task-create -p N.1`
- Expected Result:
  - Nested subtask files created: `task-0N.1.1-*.md`, `task-0N.1.2-*.md`, etc.
  - Each nested subtask has `parent: N.1` field
  - Filenames use dots as separators (not dashes)
  - First-level parent checkboxes updated with proper padding
  - Task numbering follows pattern: N.01.1, N.01.2, etc.

**Step 6: Create Third-Level Deep Nested Subtasks**
- Action: Execute `/agent-os:bert:task-create -p N.1.1`
- Expected Result:
  - Deep nested files created: `task-0N.1.1.1-*.md`, `task-0N.1.1.2-*.md`
  - Parent field correctly references `parent: N.1.1`
  - Numbering follows pattern with appropriate padding
  - File structure remains consistent

**Step 7: Verify Smart Padding**
- Action: Create a parent with more than 9 subtasks
- Expected Result:
  - Padding adjusts automatically (01, 02, ... 10, 11)
  - All task numbers sort correctly in file browser
  - Checkbox format in parent: N.01, N.02, ... N.10, N.11

**Step 8: Test Abstract Request Handler**
- Action: Execute `/agent-os:bert:task-author improve error handling in authentication`
- Expected Result:
  - System searches codebase for relevant files
  - Findings presented to user for confirmation
  - User can confirm or refine search
  - Parent task generated after confirmation
  - Task content reflects analyzed files

#### Pass Criteria
- All task files created with correct naming convention
- Smart padding works correctly at all nesting levels
- Frontmatter is valid and complete
- Task numbering is consistent and sortable
- Abstract request handling works as expected
- No errors or crashes at any step

#### Fail Criteria
- Task file creation fails
- Incorrect numbering or padding
- Invalid frontmatter
- Parent-child relationships broken
- Crashes or unexpected errors

---

### Test 6.1.2: Living Document Workflow

**Test ID:** E2E-LIVING-001
**Description:** Validate the complete workflow of creating and updating living documents with status tracking

#### Test Steps

**Step 1: Initialize Bert Session**
- Action: Execute `/agent-os:bert:start`
- Expected Result: Session initialized successfully (same as E2E-TASK-001 Step 1)

**Step 2: Generate Product Documentation with Overlay**
- Action: Execute natural language command: "run plan-product with bert overlay"
- Expected Result:
  - System recognizes natural language invocation
  - Overlay file `agent-os/bert/overlays/plan-product.md` is read
  - plan-product command executes normally
  - Overlay instructions are applied
  - Confirmation that overlay was used

**Step 3: Verify Status Comments in Generated Documents**
- Action: Open generated files (roadmap.md, mission.md, tech-stack.md)
- Expected Result:
  - All h3 (###) headings have status comments
  - Comment format: `<!-- bert:status=draft, updated=YYYY-MM-DD -->`
  - Comments appear immediately after h3 headings
  - Initial status is "draft"
  - Date is current date (YYYY-MM-DD format)
  - Comments are properly formatted HTML

**Step 4: Verify Comments Don't Affect Rendering**
- Action: View rendered markdown (if renderer available)
- Expected Result:
  - Status comments are invisible in rendered view
  - Document displays normally
  - No rendering errors or artifacts

**Step 5: Modify Section Without Bert**
- Action: Modify a section's content without using bert include
- Expected Result:
  - Content updates successfully
  - Status comment remains unchanged
  - No automatic status updates

**Step 6: Modify Section With Bert Include**
- Action: Say "Update the Completed Features section, include bert living docs"
- Expected Result:
  - System reads `agent-os/bert/includes/living-docs.md`
  - Content is modified
  - Status comment is updated
  - Status changes from "draft" to "in-progress"
  - Date updates to current date
  - Comment format preserved

**Step 7: Test Status Transitions**
- Action: Modify same section again, specify it's reviewed
- Expected Result:
  - Status changes to "reviewed"
  - Date updates
  - Transition follows rules: in-progress â†’ reviewed

**Step 8: Add Status Comment to Section Without One**
- Action: Add new h3 section, use bert include
- Expected Result:
  - New status comment added after heading
  - Status set to "in-progress"
  - Current date added
  - Proper format maintained

**Step 9: Test Multiple Natural Language Variations**
- Action: Try different invocations:
  - "include bert when updating"
  - "apply bert overlay"
  - "use bert for this change"
- Expected Result:
  - All variations trigger correct behavior
  - Include file is read and applied
  - Status comments updated appropriately

#### Pass Criteria
- Status comments inserted at all h3 headings
- Comments are properly formatted HTML
- Comments invisible in rendered markdown
- Status updates work with bert include
- Date updates automatically
- Status transitions follow defined rules
- Natural language invocation works reliably

#### Fail Criteria
- Missing status comments
- Malformed comments
- Comments visible in rendered view
- Status updates fail
- Incorrect date formats
- Natural language invocation not recognized

---

### Test 6.1.3: Combined Workflow

**Test ID:** E2E-COMBINED-001
**Description:** Validate that task authoring and living documents work together seamlessly in a realistic workflow

#### Test Steps

**Step 1: Initialize Session**
- Action: Execute `/agent-os:bert:start`
- Expected Result: Session initialized

**Step 2: Generate Living Documents**
- Action: "run plan-product with bert overlay"
- Expected Result: Documents generated with status comments

**Step 3: Use Task-Author to Identify Improvements**
- Action: `/agent-os:bert:task-author agent-os/product/roadmap.md`
- Expected Result: Parent task created with improvement suggestions

**Step 4: Create Subtasks for Improvements**
- Action: `/agent-os:bert:task-create -p N`
- Expected Result: Subtasks created for each improvement

**Step 5: Work on First Subtask**
- Action: Review subtask N.1, make changes to roadmap.md section
- Expected Result: Content updated

**Step 6: Update Living Document Section**
- Action: "Update the section we just worked on, include bert living docs"
- Expected Result:
  - Section content reflects changes
  - Status comment updated to "in-progress"
  - Date updated

**Step 7: Complete Work and Mark as Reviewed**
- Action: Finalize changes, mark section as reviewed using bert
- Expected Result:
  - Status changes to "reviewed"
  - Date updated
  - Change history preserved in status comment

**Step 8: Create Nested Subtasks for Complex Improvement**
- Action: Select complex improvement, `/agent-os:bert:task-create -p N.2`
- Expected Result: Nested subtasks created

**Step 9: Work Through Nested Tasks**
- Action: Complete nested task N.2.1, update corresponding documentation
- Expected Result:
  - Task work completed
  - Documentation updated with bert tracking
  - Status reflects progress

**Step 10: Verify Entire Workflow Cohesion**
- Action: Review all tasks and documentation
- Expected Result:
  - Task hierarchy clear and organized
  - Documentation reflects completed work
  - Status tracking shows progress
  - All files properly structured
  - Workflow feels intuitive and natural

#### Pass Criteria
- All features work together without conflicts
- Workflow is smooth and intuitive
- Task management and documentation stay synchronized
- Natural language commands work throughout
- No context loss during long workflow
- All files maintain proper structure

#### Fail Criteria
- Feature conflicts or interference
- Context loss during workflow
- Broken natural language understanding
- Task-document synchronization issues
- Workflow feels cumbersome or broken

---

## Test Execution Checklist

Before executing tests:
- [ ] All Phase 1-5 features implemented
- [ ] Test environment prepared
- [ ] Test data files created
- [ ] Test execution plan reviewed

During test execution:
- [ ] Document actual results for each step
- [ ] Screenshot or capture key outputs
- [ ] Note any deviations from expected behavior
- [ ] Record execution time for performance tracking

After test execution:
- [ ] All pass/fail criteria evaluated
- [ ] Issues logged with reproduction steps
- [ ] Test results documented
- [ ] Recommendations for improvements noted

## Test Results Template

For each test case, record:
- **Test ID**: [ID]
- **Execution Date**: [YYYY-MM-DD]
- **Executed By**: [Name]
- **Result**: [Pass/Fail/Blocked]
- **Notes**: [Any observations, issues, or recommendations]
- **Evidence**: [Screenshots, logs, file paths]

## Known Limitations

These tests cannot be executed until:
1. Phase 1: Foundation & Configuration is complete
2. Phase 2: Session Initialization System is complete
3. Phase 3: Task Author Command is complete
4. Phase 4: Enhanced Task Numbering System is complete
5. Phase 5: Living Document Tracking System is complete

## Success Metrics

- **All tests passing**: 100% pass rate required for production readiness
- **No critical issues**: Zero high-priority defects
- **Performance**: Each workflow completes in under 5 minutes
- **Usability**: Workflow feels natural and intuitive to testers
